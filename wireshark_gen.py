"""
Protococo Wireshark Lua Dissector Generator

Generates Wireshark Lua dissector code from .coco protocol definitions.
"""

from coco_ast import (
    CocoFile, Message, Field, EnumDef,
    IntegerType, BytesType, StringType, PadType, BitFieldType, EnumTypeRef,
    LiteralSize, FieldRefSize, VariableSize, GreedySize, SizeExpr,
    MatchClause, EnumValue,
)


def generate_lua_dissector(coco_file: CocoFile, message_name: str = None, stack_mode: bool = False) -> str:
    """Generate Wireshark Lua dissector code from a CocoFile.

    Args:
        coco_file: Parsed .coco file
        message_name: Optional specific message to generate (default: all top-level)
        stack_mode: If True, generate chained dissectors for layer messages

    Returns:
        Lua dissector code as string
    """
    gen = LuaGenerator(coco_file)
    if stack_mode:
        return gen.generate_stack(message_name)
    return gen.generate(message_name)


class LuaGenerator:
    """Generates Wireshark Lua dissector code."""

    def __init__(self, coco_file: CocoFile):
        self.coco = coco_file
        self.indent = 0
        self.lines = []
        self.proto_fields = []
        self.generated_fields = set()  # Track generated field var names

    def generate(self, message_name: str = None) -> str:
        """Generate complete Lua dissector."""
        self.lines = []
        self.proto_fields = []
        self.generated_fields = set()

        # Header comment
        self._emit("-- Wireshark Lua Dissector")
        self._emit("-- Generated by protococo from .coco file")
        self._emit("")

        # Determine which messages to generate
        if message_name:
            messages = [self.coco.get_message(message_name)]
            if not messages[0]:
                raise ValueError(f"Message '{message_name}' not found")
        else:
            # Generate for top-level messages (no parent)
            messages = [m for m in self.coco.messages if not m.parent]

        # Generate enum value tables
        for enum in self.coco.enums:
            self._generate_enum_table(enum)

        self._emit("")

        # Generate protocol and fields for each message
        for msg in messages:
            self._generate_protocol(msg)
            self._emit("")

        return "\n".join(self.lines)

    def generate_stack(self, root_message_name: str = None) -> str:
        """Generate chained Wireshark dissectors for layer messages.

        Creates separate Protocol objects for each layer message and uses
        DissectorTable to chain them together based on match clauses.

        Args:
            root_message_name: Root layer message (e.g., 'ethernet_frame')

        Returns:
            Lua dissector code with chained protocols
        """
        self.lines = []
        self.proto_fields = []
        self.generated_fields = set()

        # Find root message
        if root_message_name:
            root_msg = self.coco.get_message(root_message_name)
            if not root_msg:
                raise ValueError(f"Message '{root_message_name}' not found")
        else:
            # Find first layer message with no parent
            layer_messages = [m for m in self.coco.messages if m.is_layer and not m.parent]
            if not layer_messages:
                raise ValueError("No layer messages found")
            root_msg = layer_messages[0]

        # Collect all layer messages reachable from root
        layer_messages = self._collect_layer_messages(root_msg)

        # Header comment
        self._emit("-- Wireshark Lua Dissector Stack")
        self._emit("-- Generated by protococo from .coco file")
        self._emit("")

        # Generate enum value tables
        for enum in self.coco.enums:
            self._generate_enum_table(enum)
        self._emit("")

        # Generate protocol definitions for all layer messages (first pass)
        for msg in layer_messages:
            self._generate_protocol_definition_stack(msg, layer_messages)
            self._emit("")

        # Generate all registrations at the end (second pass)
        for msg in layer_messages:
            self._generate_stack_registration(msg, f"{msg.name}_proto", layer_messages)
            self._emit("")

        return "\n".join(self.lines)

    def _collect_layer_messages(self, root_msg: Message) -> list[Message]:
        """Recursively collect all layer messages reachable from root."""
        visited = set()
        result = []

        def visit(msg: Message):
            if msg.name in visited:
                return
            visited.add(msg.name)

            if msg.is_layer:
                result.append(msg)

            # Find referenced layer messages in fields
            fields = self._resolve_fields(msg)
            for field in fields:
                # Check match clause branches
                if field.match_clause:
                    for branch in field.match_clause.branches:
                        if branch.fields:
                            for bf in branch.fields:
                                if isinstance(bf.type, EnumTypeRef):
                                    ref_msg = self.coco.get_message(bf.type.enum_name)
                                    if ref_msg and ref_msg.is_layer:
                                        visit(ref_msg)

        visit(root_msg)
        return result

    def _emit(self, line: str = ""):
        """Emit a line of code."""
        if line:
            self.lines.append("    " * self.indent + line)
        else:
            self.lines.append("")

    def _generate_enum_table(self, enum: EnumDef):
        """Generate Lua table for enum values."""
        self._emit(f"local {enum.name}_values = {{")
        self.indent += 1
        for member in enum.members:
            self._emit(f"[{member.value}] = \"{member.name}\",")
        self.indent -= 1
        self._emit("}")

    def _generate_protocol(self, msg: Message):
        """Generate protocol definition for a message."""
        proto_name = msg.name
        proto_var = f"{proto_name}_proto"

        # Create protocol
        self._emit(f"-- Protocol: {msg.name}")
        self._emit(f"local {proto_var} = Proto(\"{proto_name}\", \"{proto_name.replace('_', ' ').title()}\")")
        self._emit("")

        # Collect all ProtoFields recursively
        self._emit("-- Fields")
        fields = self._resolve_fields(msg)
        self._collect_proto_fields(proto_name, fields, "")

        # Emit unique field definitions
        for pf in self.proto_fields:
            if pf['var_name'] not in self.generated_fields:
                self._emit(pf['definition'])
                self.generated_fields.add(pf['var_name'])

        self._emit("")

        # Assign fields to protocol
        field_names = [f['var_name'] for f in self.proto_fields if not f.get('skip_registration')]
        if field_names:
            # Chunk into lines of reasonable length
            self._emit(f"{proto_var}.fields = {{")
            self.indent += 1
            for name in field_names:
                self._emit(f"{name},")
            self.indent -= 1
            self._emit("}")
        self._emit("")

        # Generate dissector function
        self._generate_dissector(msg, proto_var)

        # Register with ethertype or other table if applicable
        self._generate_registration(msg, proto_var)

    def _generate_protocol_definition_stack(self, msg: Message, all_layers: list[Message]):
        """Generate protocol definition for stack mode (chained dissectors)."""
        proto_name = msg.name
        proto_var = f"{proto_name}_proto"

        # Create protocol
        self._emit(f"-- Protocol: {msg.name}")
        self._emit(f"local {proto_var} = Proto(\"{proto_name}\", \"{proto_name.replace('_', ' ').title()}\")")
        self._emit("")

        # Collect all ProtoFields recursively (but don't recurse into layer messages)
        # Clear proto_fields for this protocol (each protocol has its own fields)
        self.proto_fields = []

        self._emit("-- Fields")
        fields = self._resolve_fields(msg)
        self._collect_proto_fields_stack(proto_name, fields, "", all_layers)

        # Emit unique field definitions
        for pf in self.proto_fields:
            if pf['var_name'] not in self.generated_fields:
                self._emit(pf['definition'])
                self.generated_fields.add(pf['var_name'])

        self._emit("")

        # Assign fields to protocol
        field_names = [f['var_name'] for f in self.proto_fields if not f.get('skip_registration')]
        if field_names:
            self._emit(f"{proto_var}.fields = {{")
            self.indent += 1
            for name in field_names:
                self._emit(f"{name},")
            self.indent -= 1
            self._emit("}")
        self._emit("")

        # Generate dissector function with subdissector calls
        self._generate_dissector_stack(msg, proto_var, all_layers)

    def _resolve_fields(self, msg: Message) -> list[Field]:
        """Get all fields for a message, including inherited."""
        fields = []
        if msg.parent:
            parent = self.coco.get_message(msg.parent)
            if parent:
                fields.extend(self._resolve_fields(parent))
        fields.extend(msg.fields)
        return fields

    def _collect_proto_fields(self, proto_name: str, fields: list[Field], prefix: str):
        """Recursively collect all ProtoField definitions."""
        for field in fields:
            self._collect_field_proto_fields(proto_name, field, prefix)

    def _collect_field_proto_fields(self, proto_name: str, field: Field, prefix: str):
        """Collect ProtoField definitions for a single field."""
        field_path = f"{prefix}{field.name}" if prefix else field.name
        var_name = f"f_{proto_name}_{field_path}".replace(".", "_")
        field_type = field.type

        if isinstance(field_type, IntegerType):
            lua_type, base = self._int_type_to_lua(field_type, field)
            self.proto_fields.append({
                'var_name': var_name,
                'field_name': field.name,
                'field_path': field_path,
                'definition': f"local {var_name} = {lua_type}(\"{proto_name}.{field_path}\", \"{field.name}\", {base})",
                'size': field_type.byte_size,
                'lua_type': lua_type,
                'type': 'int',
            })

        elif isinstance(field_type, BytesType):
            self.proto_fields.append({
                'var_name': var_name,
                'field_name': field.name,
                'field_path': field_path,
                'definition': f"local {var_name} = ProtoField.bytes(\"{proto_name}.{field_path}\", \"{field.name}\")",
                'size': field.size,
                'type': 'bytes',
                'match_clause': field.match_clause,
                'structure_body': field.structure_body,
            })
            # Collect fields from match branches
            if field.match_clause:
                for branch in field.match_clause.branches:
                    if branch.fields:
                        self._collect_proto_fields(proto_name, branch.fields, f"{field_path}.")
            # Collect fields from structure body
            if field.structure_body:
                self._collect_proto_fields(proto_name, field.structure_body, f"{field_path}.")

        elif isinstance(field_type, StringType):
            self.proto_fields.append({
                'var_name': var_name,
                'field_name': field.name,
                'field_path': field_path,
                'definition': f"local {var_name} = ProtoField.string(\"{proto_name}.{field_path}\", \"{field.name}\")",
                'size': field.size,
                'type': 'string',
            })

        elif isinstance(field_type, BitFieldType):
            if field.bitfield_body:
                bit_width = field_type.bit_count
                byte_size = bit_width // 8
                lua_type = f"ProtoField.uint{bit_width}" if bit_width in [8, 16, 32, 64] else "ProtoField.uint8"

                for bf in field.bitfield_body.fields:
                    bf_var = f"f_{proto_name}_{field_path}_{bf.name}".replace(".", "_")
                    mask = self._calculate_bitmask(field.bitfield_body.fields, bf, bit_width)
                    self.proto_fields.append({
                        'var_name': bf_var,
                        'field_name': bf.name,
                        'field_path': f"{field_path}.{bf.name}",
                        'definition': f"local {bf_var} = {lua_type}(\"{proto_name}.{field_path}.{bf.name}\", \"{bf.name}\", base.DEC, nil, {mask})",
                        'size': byte_size,
                        'type': 'bitfield',
                        'parent_field': field.name,
                        'parent_path': field_path,
                        'bit_width': bit_width,
                    })
            else:
                self.proto_fields.append({
                    'var_name': var_name,
                    'field_name': field.name,
                    'field_path': field_path,
                    'definition': f"local {var_name} = ProtoField.uint8(\"{proto_name}.{field_path}\", \"{field.name}\", base.HEX)",
                    'size': 1,
                    'type': 'int',
                })

        elif isinstance(field_type, EnumTypeRef):
            enum_def = self.coco.get_enum(field_type.enum_name)
            if enum_def:
                size = self._enum_size(enum_def)
                lua_type = f"ProtoField.uint{size * 8}"
                self.proto_fields.append({
                    'var_name': var_name,
                    'field_name': field.name,
                    'field_path': field_path,
                    'definition': f"local {var_name} = {lua_type}(\"{proto_name}.{field_path}\", \"{field.name}\", base.DEC, {enum_def.name}_values)",
                    'size': size,
                    'type': 'enum',
                    'enum_name': enum_def.name,
                })
            else:
                # Embedded message - collect its fields recursively
                embedded_msg = self.coco.get_message(field_type.enum_name)
                if embedded_msg:
                    embedded_fields = self._resolve_fields(embedded_msg)
                    self._collect_proto_fields(proto_name, embedded_fields, f"{field_path}.")
                    self.proto_fields.append({
                        'var_name': var_name,
                        'field_name': field.name,
                        'field_path': field_path,
                        'definition': f"-- {var_name}: embedded message {field_type.enum_name}",
                        'type': 'message',
                        'message_name': field_type.enum_name,
                        'skip_registration': True,
                    })

    def _collect_proto_fields_stack(self, proto_name: str, fields: list[Field], prefix: str, all_layers: list[Message]):
        """Collect ProtoField definitions for stack mode (don't recurse into layer messages)."""
        layer_names = {msg.name for msg in all_layers}

        for field in fields:
            field_path = f"{prefix}{field.name}" if prefix else field.name
            var_name = f"f_{proto_name}_{field_path}".replace(".", "_")
            field_type = field.type

            # For match clauses that reference layer messages, don't collect fields from branches
            if field.match_clause:
                has_layer_branches = False
                for branch in field.match_clause.branches:
                    if branch.fields:
                        for bf in branch.fields:
                            if isinstance(bf.type, EnumTypeRef) and bf.type.enum_name in layer_names:
                                has_layer_branches = True
                                break

                if has_layer_branches:
                    # Just register the discriminator field, subdissectors will handle the rest
                    if isinstance(field_type, BytesType):
                        self.proto_fields.append({
                            'var_name': var_name,
                            'field_name': field.name,
                            'field_path': field_path,
                            'definition': f"local {var_name} = ProtoField.bytes(\"{proto_name}.{field_path}\", \"{field.name}\")",
                            'size': field.size,
                            'type': 'bytes',
                            'match_clause': field.match_clause,
                        })
                    continue

            # For non-layer fields, collect normally
            self._collect_field_proto_fields(proto_name, field, prefix)

    def _int_type_to_lua(self, int_type: IntegerType, field: Field = None) -> tuple[str, str]:
        """Convert integer type to Lua ProtoField type and base."""
        type_map = {
            'u8': 'ProtoField.uint8',
            'u16': 'ProtoField.uint16',
            'u32': 'ProtoField.uint32',
            'u64': 'ProtoField.uint64',
            'i8': 'ProtoField.int8',
            'i16': 'ProtoField.int16',
            'i32': 'ProtoField.int32',
            'i64': 'ProtoField.int64',
        }
        lua_type = type_map.get(int_type.base, 'ProtoField.uint8')
        base = "base.DEC"

        # Check for display formatter
        if field and field.attributes and field.attributes.display:
            fmt = field.attributes.display.name
            if fmt == "hex":
                base = "base.HEX"
            elif fmt == "ipv4":
                return ("ProtoField.ipv4", "nil")
            elif fmt == "port":
                base = "base.DEC"

        return (lua_type, base)

    def _enum_size(self, enum_def: EnumDef) -> int:
        """Get byte size of enum."""
        type_sizes = {'u8': 1, 'i8': 1, 'u16': 2, 'i16': 2, 'u32': 4, 'i32': 4, 'u64': 8, 'i64': 8}
        return type_sizes.get(enum_def.base_type, 1)

    def _calculate_bitmask(self, bitfields: list, target, total_bits: int = 8) -> str:
        """Calculate bitmask for a bitfield member.

        Args:
            bitfields: List of all bitfield members
            target: The specific bitfield member to calculate mask for
            total_bits: Total bit width of the bitfield (8, 16, 32, etc.)
        """
        offset = 0
        for bf in bitfields:
            if bf.name == target.name:
                mask = ((1 << bf.bit_count) - 1) << (total_bits - offset - bf.bit_count)
                hex_width = (total_bits // 4)  # 2 hex chars per byte
                return f"0x{mask:0{hex_width}X}"
            offset += bf.bit_count
        return "0xFF"

    def _size_to_lua(self, size, context_prefix: str = "") -> str:
        """Convert size spec to Lua expression."""
        if isinstance(size, LiteralSize):
            return str(size.value)
        elif isinstance(size, FieldRefSize):
            # Use the last component of the path as the Lua variable name
            # (e.g., ["header", "total_length"] -> "total_length")
            return size.field_path[-1]
        elif isinstance(size, SizeExpr):
            left = self._size_to_lua(size.left, context_prefix)
            right = self._size_to_lua(size.right, context_prefix)
            return f"({left} {size.op} {right})"
        elif isinstance(size, GreedySize):
            # Greedy size - consume rest of buffer (-1 means "to end" in Wireshark)
            return "-1"
        elif isinstance(size, VariableSize):
            return "nil"
        return "nil"

    def _generate_dissector(self, msg: Message, proto_var: str):
        """Generate dissector function."""
        self._emit(f"function {proto_var}.dissector(buffer, pinfo, tree)")
        self.indent += 1

        self._emit(f"pinfo.cols.protocol = \"{msg.name}\"")
        self._emit("")
        self._emit(f"local subtree = tree:add({proto_var}, buffer(), \"{msg.name}\")")
        self._emit("local offset = 0")
        self._emit("")

        # Generate field parsing
        fields = self._resolve_fields(msg)
        self._generate_field_parsing(fields, "subtree", "", msg.name)

        self.indent -= 1
        self._emit("end")

    def _generate_dissector_stack(self, msg: Message, proto_var: str, all_layers: list[Message]):
        """Generate dissector function for stack mode (calls subdissectors)."""
        layer_names = {msg.name for msg in all_layers}

        self._emit(f"function {proto_var}.dissector(buffer, pinfo, tree)")
        self.indent += 1

        self._emit(f"pinfo.cols.protocol = \"{msg.name}\"")
        self._emit("")
        self._emit(f"local subtree = tree:add({proto_var}, buffer(), \"{msg.name}\")")
        self._emit("local offset = 0")
        self._emit("")

        # Generate field parsing with subdissector calls
        fields = self._resolve_fields(msg)
        self._generate_field_parsing_stack(fields, "subtree", "", msg.name, layer_names)

        self.indent -= 1
        self._emit("end")

    def _generate_field_parsing_stack(self, fields: list[Field], tree_var: str, prefix: str, proto_name: str, layer_names: set):
        """Generate parsing code with subdissector calls for layer messages."""
        processed_bitfields = set()

        for field in fields:
            field_path = f"{prefix}{field.name}" if prefix else field.name
            var_name = f"f_{proto_name}_{field_path}".replace(".", "_")
            field_type = field.type

            if isinstance(field_type, IntegerType):
                size = field_type.byte_size
                is_ipv4 = field.attributes and field.attributes.display and field.attributes.display.name == "ipv4"
                if is_ipv4:
                    self._emit(f"local {field.name} = buffer(offset, {size}):ipv4()")
                else:
                    self._emit(f"local {field.name} = buffer(offset, {size}):uint()")
                self._emit(f"{tree_var}:add({var_name}, buffer(offset, {size}))")
                self._emit(f"offset = offset + {size}")
                self._emit("")

            elif isinstance(field_type, EnumTypeRef):
                # Check if this is an enum or embedded message
                enum_def = self.coco.get_enum(field_type.enum_name)
                if enum_def:
                    # Regular enum field
                    size = self._enum_size(enum_def)
                    self._emit(f"local {field.name} = buffer(offset, {size}):uint()")
                    self._emit(f"{tree_var}:add({var_name}, buffer(offset, {size}))")
                    self._emit(f"offset = offset + {size}")
                    self._emit("")
                else:
                    # Embedded message - check if it's a layer
                    embedded_msg = self.coco.get_message(field_type.enum_name)
                    if embedded_msg and embedded_msg.name not in layer_names:
                        # Non-layer embedded message - parse inline
                        self._emit(f"-- Embedded: {field.name} ({field_type.enum_name})")
                        self._emit(f"local {field.name}_start = offset")
                        embedded_fields = self._resolve_fields(embedded_msg)
                        self._generate_field_parsing_stack(embedded_fields, tree_var, f"{field_path}.", proto_name, layer_names)
                        self._emit("")

            elif isinstance(field_type, BytesType):
                # Check if match clause has layer branches
                if field.match_clause:
                    has_layer_branches = False
                    for branch in field.match_clause.branches:
                        if branch.fields:
                            for bf in branch.fields:
                                if isinstance(bf.type, EnumTypeRef) and bf.type.enum_name in layer_names:
                                    has_layer_branches = True
                                    break

                    if has_layer_branches:
                        # Generate subdissector call instead of inline parsing
                        size_expr = self._size_to_lua(field.size) if field.size else "nil"
                        if size_expr == "nil":
                            self._emit(f"local {field.name}_buf = buffer(offset)")
                            self._emit(f"local {field.name}_len = {field.name}_buf:len()")
                        else:
                            self._emit(f"local {field.name}_len = {size_expr}")
                            self._emit(f"local {field.name}_buf = buffer(offset, {field.name}_len)")

                        # Generate DissectorTable lookup and call
                        discriminator = field.match_clause.discriminator.split(".")[-1]
                        # Determine table name based on discriminator
                        table_name = self._get_dissector_table_name(field.match_clause.discriminator, proto_name)
                        self._emit(f"local {field.name}_dissector_table = DissectorTable.get(\"{table_name}\")")
                        self._emit(f"local {field.name}_dissector = {field.name}_dissector_table:get_dissector({discriminator})")
                        self._emit(f"if {field.name}_dissector then")
                        self.indent += 1
                        self._emit(f"local consumed = {field.name}_dissector:call({field.name}_buf:tvb(), pinfo, tree)")
                        if size_expr != "nil":
                            self._emit(f"offset = offset + {field.name}_len")
                        else:
                            self._emit(f"offset = offset + consumed")
                        self.indent -= 1
                        self._emit("end")
                        self._emit("")
                        continue

                # Regular bytes field handling (no layer branches)
                size_expr = self._size_to_lua(field.size) if field.size else "nil"
                if size_expr == "nil":
                    self._emit(f"local {field.name}_buf = buffer(offset)")
                    self._emit(f"local {field.name}_tree = {tree_var}:add({var_name}, {field.name}_buf)")
                else:
                    self._emit(f"local {field.name}_len = {size_expr}")
                    self._emit(f"local {field.name}_buf = buffer(offset, {field.name}_len)")
                    self._emit(f"local {field.name}_tree = {tree_var}:add({var_name}, {field.name}_buf)")
                    self._emit(f"offset = offset + {field.name}_len")
                self._emit("")

            elif isinstance(field_type, BitFieldType):
                if field_path not in processed_bitfields:
                    processed_bitfields.add(field_path)
                    bit_width = field_type.bit_count
                    byte_size = bit_width // 8
                    if field.bitfield_body:
                        self._emit(f"-- Bitfield: {field.name} ({bit_width} bits)")
                        for bf in field.bitfield_body.fields:
                            bf_var = f"f_{proto_name}_{field_path}_{bf.name}".replace(".", "_")
                            self._emit(f"{tree_var}:add({bf_var}, buffer(offset, {byte_size}))")
                        # Extract values for later use
                        bit_offset = 0
                        for bf in field.bitfield_body.fields:
                            mask = ((1 << bf.bit_count) - 1) << (bit_width - bit_offset - bf.bit_count)
                            shift = bit_width - bit_offset - bf.bit_count
                            self._emit(f"local {bf.name} = bit.band(bit.rshift(buffer(offset, {byte_size}):uint(), {shift}), {(1 << bf.bit_count) - 1})")
                            bit_offset += bf.bit_count
                        self._emit(f"offset = offset + {byte_size}")
                    else:
                        self._emit(f"{tree_var}:add({var_name}, buffer(offset, {byte_size}))")
                        self._emit(f"offset = offset + {byte_size}")
                    self._emit("")

            elif isinstance(field_type, EnumTypeRef):
                enum_def = self.coco.get_enum(field_type.enum_name)
                if enum_def:
                    size = self._enum_size(enum_def)
                    self._emit(f"local {field.name} = buffer(offset, {size}):uint()")
                    self._emit(f"{tree_var}:add({var_name}, buffer(offset, {size}))")
                    self._emit(f"offset = offset + {size}")
                    self._emit("")

    def _get_dissector_table_name(self, discriminator_path: str, proto_name: str) -> str:
        """Generate DissectorTable name from discriminator path."""
        # Common mappings
        if "ethertype" in discriminator_path:
            return "ethertype"
        elif "protocol" in discriminator_path:
            return "ip.proto"
        elif "next_header" in discriminator_path:
            return "ip.proto"
        # Default: use protocol name + discriminator field
        field_name = discriminator_path.split(".")[-1]
        return f"{proto_name}.{field_name}"

    def _generate_field_parsing(self, fields: list[Field], tree_var: str, prefix: str, proto_name: str):
        """Generate parsing code for fields."""
        processed_bitfields = set()

        for field in fields:
            field_path = f"{prefix}{field.name}" if prefix else field.name
            var_name = f"f_{proto_name}_{field_path}".replace(".", "_")
            field_type = field.type

            if isinstance(field_type, IntegerType):
                size = field_type.byte_size
                # Check for ipv4 display
                is_ipv4 = field.attributes and field.attributes.display and field.attributes.display.name == "ipv4"
                if is_ipv4:
                    self._emit(f"local {field.name} = buffer(offset, {size}):ipv4()")
                else:
                    self._emit(f"local {field.name} = buffer(offset, {size}):uint()")
                self._emit(f"{tree_var}:add({var_name}, buffer(offset, {size}))")
                self._emit(f"offset = offset + {size}")
                self._emit("")

            elif isinstance(field_type, BytesType):
                size_expr = self._size_to_lua(field.size) if field.size else "nil"

                if size_expr == "nil":
                    self._emit(f"local {field.name}_buf = buffer(offset)")
                    self._emit(f"local {field.name}_tree = {tree_var}:add({var_name}, {field.name}_buf)")
                else:
                    self._emit(f"local {field.name}_len = {size_expr}")
                    self._emit(f"local {field.name}_buf = buffer(offset, {field.name}_len)")
                    self._emit(f"local {field.name}_tree = {tree_var}:add({var_name}, {field.name}_buf)")
                    self._emit(f"offset = offset + {field.name}_len")

                # Handle match clause
                if field.match_clause:
                    self._generate_match_parsing(field.match_clause, f"{field.name}_buf", f"{field.name}_tree", f"{field_path}.", proto_name)
                # Handle structure body
                elif field.structure_body:
                    self._emit(f"local {field.name}_offset = 0")
                    self._generate_structure_parsing(field.structure_body, f"{field.name}_tree", f"{field.name}_buf", f"{field.name}_offset", f"{field_path}.", proto_name)

                self._emit("")

            elif isinstance(field_type, StringType):
                size_expr = self._size_to_lua(field.size) if field.size else "nil"
                if size_expr == "nil":
                    self._emit(f"{tree_var}:add({var_name}, buffer(offset))")
                else:
                    self._emit(f"{tree_var}:add({var_name}, buffer(offset, {size_expr}))")
                    self._emit(f"offset = offset + {size_expr}")
                self._emit("")

            elif isinstance(field_type, BitFieldType):
                if field_path not in processed_bitfields:
                    processed_bitfields.add(field_path)
                    bit_width = field_type.bit_count
                    byte_size = bit_width // 8
                    if field.bitfield_body:
                        self._emit(f"-- Bitfield: {field.name} ({bit_width} bits)")
                        for bf in field.bitfield_body.fields:
                            bf_var = f"f_{proto_name}_{field_path}_{bf.name}".replace(".", "_")
                            self._emit(f"{tree_var}:add({bf_var}, buffer(offset, {byte_size}))")
                        # Extract values for later use
                        bit_offset = 0
                        for bf in field.bitfield_body.fields:
                            mask = ((1 << bf.bit_count) - 1) << (bit_width - bit_offset - bf.bit_count)
                            shift = bit_width - bit_offset - bf.bit_count
                            self._emit(f"local {bf.name} = bit.band(bit.rshift(buffer(offset, {byte_size}):uint(), {shift}), {(1 << bf.bit_count) - 1})")
                            bit_offset += bf.bit_count
                        self._emit(f"offset = offset + {byte_size}")
                    else:
                        self._emit(f"{tree_var}:add({var_name}, buffer(offset, {byte_size}))")
                        self._emit(f"offset = offset + {byte_size}")
                    self._emit("")

            elif isinstance(field_type, EnumTypeRef):
                enum_def = self.coco.get_enum(field_type.enum_name)
                if enum_def:
                    size = self._enum_size(enum_def)
                    self._emit(f"local {field.name} = buffer(offset, {size}):uint()")
                    self._emit(f"{tree_var}:add({var_name}, buffer(offset, {size}))")
                    self._emit(f"offset = offset + {size}")
                    self._emit("")
                else:
                    # Embedded message - expand inline
                    embedded_msg = self.coco.get_message(field_type.enum_name)
                    if embedded_msg:
                        self._emit(f"-- Embedded: {field.name} ({field_type.enum_name})")
                        self._emit(f"local {field.name}_start = offset")
                        self._emit(f"local {field.name}_tree = {tree_var}:add(buffer(offset), \"{field.name}\")")
                        embedded_fields = self._resolve_fields(embedded_msg)
                        self._generate_field_parsing(embedded_fields, f"{field.name}_tree", f"{field_path}.", proto_name)
                        self._emit(f"{field.name}_tree:set_len(offset - {field.name}_start)")
                        self._emit("")

    def _generate_structure_parsing(self, fields: list[Field], tree_var: str, buf_var: str, offset_var: str, prefix: str, proto_name: str):
        """Generate parsing for a structure body using a sub-buffer."""
        for field in fields:
            field_path = f"{prefix}{field.name}"
            var_name = f"f_{proto_name}_{field_path}".replace(".", "_")
            field_type = field.type

            if isinstance(field_type, IntegerType):
                size = field_type.byte_size
                self._emit(f"local {field.name} = {buf_var}({offset_var}, {size}):uint()")
                self._emit(f"{tree_var}:add({var_name}, {buf_var}({offset_var}, {size}))")
                self._emit(f"{offset_var} = {offset_var} + {size}")

            elif isinstance(field_type, EnumTypeRef):
                enum_def = self.coco.get_enum(field_type.enum_name)
                if enum_def:
                    size = self._enum_size(enum_def)
                    self._emit(f"local {field.name} = {buf_var}({offset_var}, {size}):uint()")
                    self._emit(f"{tree_var}:add({var_name}, {buf_var}({offset_var}, {size}))")
                    self._emit(f"{offset_var} = {offset_var} + {size}")
                else:
                    # Embedded message
                    embedded_msg = self.coco.get_message(field_type.enum_name)
                    if embedded_msg:
                        self._emit(f"local {field.name}_tree = {tree_var}:add({buf_var}({offset_var}), \"{field.name}\")")
                        embedded_fields = self._resolve_fields(embedded_msg)
                        self._generate_structure_parsing(embedded_fields, f"{field.name}_tree", buf_var, offset_var, f"{field_path}.", proto_name)

            elif isinstance(field_type, BytesType):
                size_expr = self._size_to_lua(field.size) if field.size else "nil"
                if size_expr == "nil":
                    self._emit(f"{tree_var}:add({var_name}, {buf_var}({offset_var}))")
                else:
                    self._emit(f"local {field.name}_len = {size_expr}")
                    self._emit(f"{tree_var}:add({var_name}, {buf_var}({offset_var}, {field.name}_len))")
                    self._emit(f"{offset_var} = {offset_var} + {field.name}_len")

            elif isinstance(field_type, BitFieldType):
                if field.bitfield_body:
                    bit_width = field_type.bit_count
                    byte_size = bit_width // 8
                    for bf in field.bitfield_body.fields:
                        bf_var = f"f_{proto_name}_{field_path}_{bf.name}".replace(".", "_")
                        self._emit(f"{tree_var}:add({bf_var}, {buf_var}({offset_var}, {byte_size}))")
                    self._emit(f"{offset_var} = {offset_var} + {byte_size}")

    def _generate_match_parsing(self, match_clause: MatchClause, buf_var: str, tree_var: str, prefix: str, proto_name: str):
        """Generate if/elseif dispatch for match clause with full parsing."""
        # Use the last component of the path as the Lua variable name
        # (e.g., "header.protocol" -> "protocol" since that's how it was defined)
        discriminator = match_clause.discriminator.split(".")[-1]
        self._emit("")
        self._emit(f"-- Match on {match_clause.discriminator}")
        self._emit(f"local {prefix.replace('.', '_')}offset = 0")

        first = True
        for branch in match_clause.branches:
            if branch.pattern is None:
                self._emit("else")
                self.indent += 1
                self._emit("-- Default: raw bytes")
                self.indent -= 1
            else:
                pattern = self._pattern_to_lua(branch.pattern)
                if first:
                    self._emit(f"if {discriminator} == {pattern} then")
                    first = False
                else:
                    self._emit(f"elseif {discriminator} == {pattern} then")

                self.indent += 1
                if branch.fields:
                    offset_var = f"{prefix.replace('.', '_')}offset"
                    self._generate_structure_parsing(branch.fields, tree_var, buf_var, offset_var, prefix, proto_name)
                self.indent -= 1

        self._emit("end")

    def _pattern_to_lua(self, pattern) -> str:
        """Convert match pattern to Lua expression."""
        if isinstance(pattern, int):
            return str(pattern)
        elif isinstance(pattern, EnumValue):
            enum_def = self.coco.get_enum(pattern.enum_name)
            if enum_def:
                member = enum_def.get_member_by_name(pattern.member_name)
                if member:
                    return str(member.value)
            return f"0 --[[{pattern.enum_name}.{pattern.member_name}]]"
        return str(pattern)

    def _generate_registration(self, msg: Message, proto_var: str):
        """Generate dissector registration code."""
        self._emit("")
        self._emit("-- Registration")

        if 'ethernet' in msg.name.lower():
            self._emit("-- To register with Ethernet:")
            self._emit("-- local eth_table = DissectorTable.get(\"wtap_encap\")")
            self._emit(f"-- eth_table:add(wtap_encaps.ETHERNET, {proto_var})")
        elif 'ipv4' in msg.name.lower() or 'ip' in msg.name.lower():
            self._emit("-- To register with IP:")
            self._emit("-- local ip_table = DissectorTable.get(\"ip.proto\")")
            self._emit(f"-- ip_table:add(6, {proto_var})  -- TCP")

        self._emit(f"-- Or use: Analyze -> Decode As -> {msg.name}")

    def _generate_stack_registration(self, msg: Message, proto_var: str, all_layers: list[Message]):
        """Generate DissectorTable creation and registration for stack mode."""
        layer_names = {m.name for m in all_layers}
        self._emit("")
        self._emit("-- DissectorTable Registration")

        # Register subdissectors for this protocol's discriminator fields
        fields = self._resolve_fields(msg)
        for field in fields:
            if field.match_clause:
                # Check if any branches reference layer messages
                has_layer_branches = False
                for branch in field.match_clause.branches:
                    if branch.fields:
                        for bf in branch.fields:
                            if isinstance(bf.type, EnumTypeRef) and bf.type.enum_name in layer_names:
                                has_layer_branches = True
                                break

                if has_layer_branches:
                    # Get or create DissectorTable for this discriminator
                    table_name = self._get_dissector_table_name(field.match_clause.discriminator, msg.name)

                    # Standard Wireshark tables (ethertype, ip.proto) already exist
                    if table_name in ["ethertype", "ip.proto"]:
                        self._emit(f"local {msg.name}_table = DissectorTable.get(\"{table_name}\")")
                    else:
                        # Custom table - create it
                        self._emit(f"local {msg.name}_table = DissectorTable.new(\"{table_name}\", \"{msg.name.replace('_', ' ').title()} Type\", ftypes.UINT16)")
                    self._emit("")

                    # Generate registration code for each layer branch
                    for branch in field.match_clause.branches:
                        if branch.pattern and branch.fields:
                            for bf in branch.fields:
                                if isinstance(bf.type, EnumTypeRef) and bf.type.enum_name in layer_names:
                                    pattern_value = self._pattern_to_lua(branch.pattern)
                                    layer_proto_var = f"{bf.type.enum_name}_proto"
                                    self._emit(f"{msg.name}_table:add({pattern_value}, {layer_proto_var})")

        # Register this protocol with parent's DissectorTable
        # Determine registration based on message's default values
        registration_info = self._get_registration_info(msg)
        if registration_info:
            table_name, value, comment = registration_info
            self._emit(f"-- Register with {comment}")
            self._emit(f"local parent_table = DissectorTable.get(\"{table_name}\")")
            self._emit(f"if parent_table then")
            self.indent += 1
            self._emit(f"parent_table:add({value}, {proto_var})")
            self.indent -= 1
            self._emit("end")
        else:
            # Root layer or unknown parent - register with wtap_encap
            if 'ethernet' in msg.name.lower():
                self._emit("-- Root layer: register with wtap_encap")
                self._emit("local wtap_encap_table = DissectorTable.get(\"wtap_encap\")")
                self._emit("if wtap_encap_table then")
                self.indent += 1
                self._emit(f"wtap_encap_table:add(wtap_encaps.ETHERNET, {proto_var})")
                self.indent -= 1
                self._emit("end")
            else:
                self._emit(f"-- Or use: Analyze -> Decode As -> {msg.name}")

    def _get_registration_info(self, msg: Message) -> tuple[str, str, str] | None:
        """Get DissectorTable registration info from message's default values.

        Returns: (table_name, value, comment) or None
        """
        fields = self._resolve_fields(msg)
        for field in fields:
            # Look for enum default values that indicate parent layer registration
            if field.default_value and isinstance(field.default_value, EnumValue):
                enum_def = self.coco.get_enum(field.default_value.enum_name)
                if enum_def:
                    member = enum_def.get_member_by_name(field.default_value.member_name)
                    if member:
                        value = str(member.value)
                        # Determine table based on enum type
                        if enum_def.name == "EtherType":
                            return ("ethertype", value, "Ethernet EtherType")
                        elif enum_def.name == "Protocol":
                            return ("ip.proto", value, "IP Protocol")
                        elif "TcpOptKind" in enum_def.name:
                            return ("tcp.option_kind", value, "TCP Option Kind")
        return None
